{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation of required packages (uncomment only if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#!{sys.executable} -m pip install pydub\n",
    "#!{sys.executable} -m pip install google-cloud-speech\n",
    "#!{sys.executable} -m pip install google-cloud-storage\n",
    "#!{sys.executable} -m pip install google-oauth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "import wave\n",
    "from pydub import AudioSegment\n",
    "\n",
    "from google.cloud import speech \n",
    "from google.cloud import storage \n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "from google.oauth2 import service_account\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Speech-to-Text API functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credential_file = 'credentials-neuromod.json' #To create after creating a google account. The algorithm cannot work without it\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(credential_file)\n",
    "client = speech.SpeechClient(credentials = credentials)\n",
    "storage_client = storage.Client.from_service_account_json(credential_file)\n",
    "bucketname = \"neuromodvideo\"\n",
    "        \n",
    "def get_frame_rate(audio_file_name):\n",
    "    \"\"\"Return the frame rate of the audio file\"\"\"\n",
    "    with wave.open(audio_file_name, \"rb\") as wave_file:\n",
    "        frame_rate = wave_file.getframerate()\n",
    "        return frame_rate\n",
    "    \n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "    \n",
    "def delete_blob(bucket_name, blob_name):\n",
    "    \"\"\"Deletes a blob from the bucket.\"\"\"\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.delete()\n",
    "    \n",
    "def google_transcribe(audio_file, time_init, words_from_the_subtitles):\n",
    "    \"\"\"Return a transcript with timestamp for the audio file studied relative to time_init (the time the sentence appears in the the studied audio segment)\"\"\"\n",
    "    \n",
    "    frame_rate = get_frame_rate(audio_file)\n",
    "    bucket_name = bucketname\n",
    "    source_file_name = audio_file\n",
    "    destination_blob_name = audio_file\n",
    "    \n",
    "    upload_blob(bucket_name, source_file_name, destination_blob_name)\n",
    "    gcs_uri = 'gs://' + bucketname + '/' + audio_file\n",
    "    audio = types.RecognitionAudio(uri = gcs_uri)\n",
    "\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=frame_rate,\n",
    "        language_code='en-US',\n",
    "        speech_contexts = [{\"phrases\": words_from_the_subtitles}],\n",
    "        enable_word_time_offsets=True,\n",
    "        enable_automatic_punctuation=True)\n",
    "\n",
    "    # Detects speech in the audio file\n",
    "    operation = client.long_running_recognize(config, audio)\n",
    "    response = operation.result(timeout=10000)\n",
    "    transcript = []\n",
    "    if len(response.results) > 0:\n",
    "        result = response.results[0] \n",
    "        words_info = result.alternatives[0].words \n",
    "        for word_info in words_info:\n",
    "            start_time = word_info.start_time\n",
    "            time = start_time.seconds + start_time.nanos * 1e-9\n",
    "            time_adjusted = round(time_init/1000 + time, 1)\n",
    "            transcript.append([time_adjusted, word_info.word])\n",
    "\n",
    "    delete_blob(bucket_name, destination_blob_name)\n",
    "    return transcript\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions used in the following parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(word):\n",
    "    return word.lower().replace(',', '').replace('.', '').replace('?', '').replace('!', '')\n",
    "\n",
    "def decomposition_time(line):\n",
    "    start_str, end_str = line.split(\" --> \")\n",
    "    start = list(map(int, start_str.replace(',', ':').split(':')))\n",
    "    end = list(map(int, end_str.replace(',', ':').split(':')))\n",
    "    start_time = start[3]+1000*start[2]+60000*start[1]+3600000*start[0]\n",
    "    end_time = end[3]+1000*end[2]+60000*end[1]+3600000*end[0]\n",
    "    return start_time, end_time\n",
    "\n",
    "def remove_charac_and_split(words):\n",
    "    sentence_clean = words.replace('- ', ' ') \n",
    "    if ':' in sentence_clean:\n",
    "        sentence_clean = sentence_clean.split(': ')[-1]    \n",
    "    while \"(\" in sentence_clean:\n",
    "        i1 = sentence_clean.index(\"(\")\n",
    "        i2 = sentence_clean.index(\")\")\n",
    "        sentence_clean = sentence_clean[:i1] + sentence_clean[i2+1:]\n",
    "    while \"<\" in sentence_clean:\n",
    "        i1 = sentence_clean.index(\"<\")\n",
    "        i2 = sentence_clean.index(\">\")\n",
    "        sentence_clean = sentence_clean[:i1] + sentence_clean[i2+1:]\n",
    "    return sentence_clean.strip().split()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find shift between the audio and the subtitles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following parts, a positive shift means that for a given sentence, the time of its appearance in the audio is less than the time of its appearance in the subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_first_words_from_subtitles(subtitles_file):\n",
    "    \"\"\"Create a list of the first words of each sentence with timestamp from the subtitles file. Only the timestamp for the first words of each sentence is available in this file\"\"\"\n",
    "    subtitles = open(subtitles_file)\n",
    "    sentences = []\n",
    "    for line in subtitles:\n",
    "        line = line.replace('\\n','').replace('\\t','')\n",
    "        if line.isdigit():\n",
    "            sentences.append([0,\"\"])\n",
    "        elif \"-->\" in line:\n",
    "            sentences[-1][0] = decomposition_time(line)[0]\n",
    "        elif sentences[-1][1] != \"\" and line != \"\":\n",
    "            sentences[-1][1] += \" \" + line \n",
    "        else:\n",
    "            sentences[-1][1] += line    \n",
    "    list_first_words = [[sentence[0], remove_charac_and_split(sentence[1])] for sentence in sentences]\n",
    "    for i in reversed(range(len(list_first_words))):\n",
    "        if len(list_first_words[i][1]) == 0:\n",
    "            list_first_words.pop(i)\n",
    "        else:\n",
    "            list_first_words[i][1] = remove_punctuation(list_first_words[i][1][0])\n",
    "    return list_first_words\n",
    "\n",
    "\n",
    "def list_words_from_audio(audio_file):\n",
    "    \"\"\"Create a list of words with timestamp from the audio file using Google Speech-to-Text API\"\"\"\n",
    "    sound = AudioSegment.from_file(audio_file)\n",
    "    n_pas = len(sound) // 10000\n",
    "    list_words = []\n",
    "    for i in range(n_pas):\n",
    "        seg = sound[10000*i:10000*(i+1)]\n",
    "        temp_file_name = \"temp_audio_processing.wav\"\n",
    "        seg.export(temp_file_name, format=\"wav\")      \n",
    "        transcript = google_transcribe(temp_file_name, 10000*i, [''])\n",
    "        for pair in transcript:\n",
    "            pair[1] = remove_punctuation(pair[1]).strip().replace('-', ' ')\n",
    "            pair[0] = int(pair[0]*1000)\n",
    "            list_words.append(pair)\n",
    "        os.remove(temp_file_name)\n",
    "    return list_words \n",
    "\n",
    "\n",
    "def find_shift(subtitles_file, audio_file, precision = 300):\n",
    "    \"\"\"Find the best shift between the audio and the subtitles. Return the shift in ms and the number of words in common between the two list of words using this shift and a given precision in ms\"\"\"\n",
    "    \n",
    "    list_from_audio = list_words_from_audio(audio_file)\n",
    "    list_from_subtitles = list_first_words_from_subtitles(subtitles_file)\n",
    "    \n",
    "    def min_ind(list_first, mini):\n",
    "        \"\"\"Function used only once to compute indices efficiently\"\"\"\n",
    "        ind_min = 0\n",
    "        ind_max = len(list_first) - 1\n",
    "        ind = int((ind_min + ind_max)/2)\n",
    "        while (ind_max - ind_min) > 1:\n",
    "            if list_first[ind][0] > mini:\n",
    "                ind_max = ind\n",
    "            elif list_first[ind][0] < mini:\n",
    "                ind_min = ind\n",
    "            else:\n",
    "                return ind\n",
    "            ind = int((ind_min + ind_max)/2)       \n",
    "        return ind\n",
    "    \n",
    "    scoremax = 0\n",
    "    bestshift = 0\n",
    "    \n",
    "    for i in range(len(list_from_audio)):\n",
    "        word = list_from_audio[i][1]\n",
    "        list_ind = [idx for idx,e in enumerate(list_from_subtitles) if e[1] == word]\n",
    "        for j in list_ind:\n",
    "            shift = list_from_subtitles[j][0] - list_from_audio[i][0]  \n",
    "            score = 0\n",
    "            for word in list_from_audio:\n",
    "                for k in range(min_ind(list_from_subtitles, word[0] + shift - precision) - 1, min_ind(list_from_subtitles, word[0] + shift + precision) + 2):\n",
    "                    if list_from_subtitles[k][0] - precision < word[0] + shift < list_from_subtitles[k][0] + precision:\n",
    "                        if word[1] == list_from_subtitles[k][1]:\n",
    "                            score+=1\n",
    "            if score > scoremax:\n",
    "                scoremax = score\n",
    "                bestshift = shift\n",
    "                \n",
    "    return bestshift, scoremax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the timestamps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp(subtitles_file, audio_file, shift, path):\n",
    "    \n",
    "    #Opening the files: subtitles, audio and path to write the transcript\n",
    "    subtitles = open(subtitles_file)\n",
    "    sound = AudioSegment.from_file(audio_file)\n",
    "    f = open(path,\"w\")\n",
    "    f.close()\n",
    "\n",
    "    #Getting the sentences and their timestamp from the subtitles\n",
    "    sentences = []\n",
    "    for line in subtitles:\n",
    "        line = line.replace('\\n','').replace('\\t','')\n",
    "        if line.isdigit():\n",
    "            sentences.append([0,0,\"\"])\n",
    "        elif \"-->\" in line:\n",
    "            sentences[-1][0] = decomposition_time(line)[0]\n",
    "            sentences[-1][1] = decomposition_time(line)[1]\n",
    "        elif sentences[-1][2] != \"\" and line != \"\":\n",
    "            sentences[-1][2] += \" \" + line \n",
    "        else:\n",
    "            sentences[-1][2] += line\n",
    "     \n",
    "    #For each sentence, getting the precise timestamp using Google Speech-to-Text API\n",
    "    for sentence in sentences:\n",
    "        start_time = sentence[0] - shift - 200\n",
    "        end_time = sentence[1] - shift + 200\n",
    "        if start_time > 0 and end_time < len(sound):\n",
    "            words = remove_charac_and_split(sentence[2])\n",
    "            if len(words) > 0:\n",
    "                \n",
    "                #Getting words and timestamp from the API\n",
    "                seg = sound[start_time:end_time]\n",
    "                temp_file_name = \"temp_audio_processing.wav\"\n",
    "                seg.export(temp_file_name, format=\"wav\")\n",
    "                transcript = google_transcribe(temp_file_name, start_time, words)\n",
    "                os.remove(temp_file_name)\n",
    "                start_time += 200\n",
    "                \n",
    "                #Removing punctuation\n",
    "                words_from_subtitles = [remove_punctuation(word) for word in words]\n",
    "                transcript_from_api = [[element[0], remove_punctuation(element[1])] for element in transcript]\n",
    "\n",
    "                #Keeping only words found by the API which are in the subtitles and present once\n",
    "                to_remove=[]\n",
    "                for i in range(len(transcript_from_api)):\n",
    "                    word = transcript_from_api[i][1]\n",
    "                    if words_from_subtitles.count(word)!= 1:\n",
    "                        to_remove.append(i)\n",
    "                    for j in range(i+1, len(transcript_from_api)):\n",
    "                        if transcript_from_api[j][1] == word:\n",
    "                            to_remove.append(j)\n",
    "                            to_remove.append(i)\n",
    "                for i in reversed(sorted(np.unique(to_remove))):\n",
    "                    transcript_from_api.pop(i)\n",
    "\n",
    "                #Getting the exact timestamp when possible\n",
    "                timestamp = [round(start_time/1000, 1)] + [0] * (len(words_from_subtitles) - 1)\n",
    "                ind_known = {0}\n",
    "                for i in range(len(transcript_from_api)):\n",
    "                    ind = words_from_subtitles.index(transcript_from_api[i][1])\n",
    "                    timestamp[ind] = round(transcript_from_api[i][0], 1)\n",
    "                    ind_known.add(ind)\n",
    "                ind_known = sorted(list(ind_known))\n",
    "\n",
    "                #Interpollate the rest of the timestamp\n",
    "                i = -1\n",
    "                for j in range(len(words_from_subtitles)):\n",
    "                    if j in ind_known :\n",
    "                        i += 1\n",
    "                    elif j < ind_known[-1]:\n",
    "                        timestamp[j] = round((timestamp[ind_known[i]] + (j - ind_known[i])*(timestamp[ind_known[i+1]] - timestamp[ind_known[i]])/(ind_known[i+1]-ind_known[i])), 1)\n",
    "                    else:\n",
    "                        timestamp[j] = round(timestamp[j-1]+0.2, 1) \n",
    "                        \n",
    "                #If the result is not coherent, use linear interpollation\n",
    "                if sorted(timestamp) != timestamp:\n",
    "                    timestamp = [round(start_time/1000 + 2*i, 1)  for i in range(len(words_from_subtitles))]\n",
    "                \n",
    "                #Writing the words and the timestamp in the desired file\n",
    "                to_write = ''\n",
    "                for i in range(len(words)):\n",
    "                    to_write += str(timestamp[i]) + ': ' + words[i] + '\\n'\n",
    "                f = open(path,\"a\")\n",
    "                f.write(to_write + '\\n')\n",
    "                f.close()\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing this code with an exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subtitles_file = \"subtitles/bourne_supremacy_subtitles.srt\" #To edit: subtitles of the studied movies\n",
    "audio_file = \"movies_audio/bourne_supremacy/bourne_supremacy_seg01_mono.wav\" #To edit: audio segment studied\n",
    "shift = find_shift(subtitles_file, audio_file, precision = 300)[0] #Not necessary to recompute everytime once this is known\n",
    "transcript_with_timestamp_to_create_filename = \"movies_transcripts/bourne_supremacy/bourne_supremacy_seg01_mono.txt\" #To edit\n",
    "\n",
    "get_timestamp(subtitles_file, audio_file, shift, transcript_with_timestamp_to_create_filename) #Should take nearly 20min for an audio file of 10 min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
